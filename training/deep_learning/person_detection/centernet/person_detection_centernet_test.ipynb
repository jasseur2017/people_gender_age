{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5485571",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ee7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.augmentations.geometric.functional as F\n",
    "import cv2\n",
    "\n",
    "class AspectRatioResize(A.DualTransform):\n",
    "    \"\"\"Resize the input to the given height and width.\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of applying the transform. Default: 1.\n",
    "        height (int): desired height of the output.\n",
    "        width (int): desired width of the output.\n",
    "        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
    "            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
    "            Default: cv2.INTER_LINEAR.\n",
    "\n",
    "    Targets:\n",
    "        image, mask, bboxes\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, height, width, interpolation=cv2.INTER_LINEAR, always_apply=False, p=1):\n",
    "        super(AspectRatioResize, self).__init__(always_apply, p)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def apply(self, img, interpolation=cv2.INTER_LINEAR, **params):\n",
    "        height, width, _ = img.shape\n",
    "        r = min(self.width / width, self.height / height)\n",
    "        return F.resize(\n",
    "            img, height=int(r * height), width=int(r * width), interpolation=interpolation\n",
    "        )\n",
    "\n",
    "    def apply_to_bbox(self, bbox, **params):\n",
    "        # Bounding box coordinates are scale invariant\n",
    "        return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "IMAGE_SIZE = (1088, 608)\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        AspectRatioResize(height=IMAGE_SIZE[1], width=IMAGE_SIZE[0], p=1.0),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=IMAGE_SIZE[1], min_width=IMAGE_SIZE[0], border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=[128, 128, 128]\n",
    "        )\n",
    "#         A.Resize(height=IMAGE_SIZE[1], width=IMAGE_SIZE[0], p=1.0)\n",
    "    ],\n",
    "    p=1.0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74ef077d",
   "metadata": {},
   "source": [
    "## Crowd human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaa70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "crowd_data_dir = Path(\"/home/jasseur/Downloads/crowdhuman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crowd_test_file = Path(\"../../../data/crowdhuman/annotation_val_with_classes.csv\")\n",
    "crowd_test_df = pd.read_csv(crowd_test_file)\n",
    "crowd_test_df = pd.DataFrame(crowd_test_df[\"id\"].unique(), columns=[\"id\"])\n",
    "crowd_test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918535ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.test_dataset import TestDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "crowd_test_dir = Path(crowd_data_dir, \"Images\")\n",
    "crowd_test_dataset = TestDataset(crowd_test_dir, crowd_test_df, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "image_name, image, image_size = crowd_test_dataset[0].values()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9cc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd200853",
   "metadata": {},
   "source": [
    "## Khaliji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2492847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "khaliji_data_dir = Path(\"../../../data/khaliji\")\n",
    "!ls $khaliji_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.test_dataset import TestDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "khaliji_test_dir = Path(khaliji_data_dir, \"Images\")\n",
    "khaliji_test_df = pd.DataFrame(\n",
    "    list(image_path.stem for image_path in khaliji_test_dir.iterdir()),\n",
    "    columns=[\"id\"]\n",
    ")\n",
    "khaliji_test_dataset = TestDataset(khaliji_test_dir, khaliji_test_df, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(khaliji_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c915208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "image_name, image, image_size = khaliji_test_dataset[0].values()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5cff29a",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pose_dla_dcn import get_pose_net as get_dla_dcn\n",
    "from src.trainer import Trainer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "num_layers = 34\n",
    "heads = {\"hm\": 1, \"wh\": 4, \"reg\": 2}\n",
    "head_conv = 256\n",
    "net = get_dla_dcn(num_layers, heads, head_conv)\n",
    "model_path = Path(\"checkpoint\", \"10.pth\")\n",
    "# model_path = Path(data_dir, \"fairmot_dla34.pth\")\n",
    "trainer = Trainer(\n",
    "    net, image_size=IMAGE_SIZE, device=\"cuda:1\", checkpoint_dir=None, model_path=model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe36c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = trainer.predict(khaliji_test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"fbox\"] = test_df[[\"center\", \"dimension\"]].apply(\n",
    "    lambda d: str([\n",
    "        int(d[\"center\"][0] - d[\"dimension\"][0]),\n",
    "        int(d[\"center\"][1] - d[\"dimension\"][1]),\n",
    "        int(d[\"dimension\"][0] + d[\"dimension\"][2]),\n",
    "        int(d[\"dimension\"][1] + d[\"dimension\"][3])\n",
    "    ]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32809a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        AspectRatioResize(height=IMAGE_SIZE[1], width=IMAGE_SIZE[0], p=1.0),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=IMAGE_SIZE[1], min_width=IMAGE_SIZE[0], border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=[128, 128, 128]\n",
    "        )\n",
    "#         A.Resize(height=IMAGE_SIZE[1], width=IMAGE_SIZE[0], p=1.0)\n",
    "    ],\n",
    "    p=1.0,\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"pascal_voc\",\n",
    "        min_area=0,\n",
    "        min_visibility=0,\n",
    "        label_fields=[]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f97643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_dataset import TrainDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_dataset = TrainDataset(khaliji_test_dir, test_df, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "image, centers, dimensions = train_dataset[8].values()\n",
    "for center, dimension in zip(centers, dimensions):\n",
    "    x, y = map(int, center)\n",
    "    l, t, r, b = map(int, dimension)\n",
    "    cv2.rectangle(\n",
    "        image, (x - l, y - t), (x + r, y + b), (1.0, 0.0, 0.0), 2\n",
    "    )\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc6f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
