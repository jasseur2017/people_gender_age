{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lK58y2L3Xekd"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5kRk5_9sXuYJ"
   },
   "source": [
    "### MOT15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/home/username/Downloads/MOT15\")\n",
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_mot15_df = pd.read_csv(Path(data_dir, \"annotation_train.csv\"))\n",
    "train_mot15_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# IMAGE_SIZE = (416, 416)\n",
    "IMAGE_SIZE = (1088, 608)\n",
    "# IMAGE_SIZE = (608, 608)\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_SIZE[1], width=IMAGE_SIZE[0], p=1.0),\n",
    "    ], \n",
    "    p=1.0, \n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"pascal_voc\",\n",
    "        min_area=0,\n",
    "        min_visibility=0,\n",
    "        label_fields=[\"person_ids\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_SIZE[1], width=IMAGE_SIZE[0], p=1.0),\n",
    "    ],\n",
    "    p=1.0,\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"pascal_voc\",\n",
    "        min_area=0,\n",
    "        min_visibility=0,\n",
    "        label_fields=[\"person_ids\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_dataset import TrainDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_mot15_dir = Path(data_dir, \"train\")\n",
    "train_dataset = TrainDataset(train_mot15_dir, train_mot15_df, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrOBZmdKYPsX"
   },
   "outputs": [],
   "source": [
    "def get_color(idx):\n",
    "    idx = idx * 3\n",
    "    color = ((37 * idx) % 255 / 255, (17 * idx) % 255 / 255, (29 * idx) % 255 / 255)\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "image, centers, person_ids = train_dataset[25].values()\n",
    "for center, person_id in zip(centers.tolist(), person_ids.tolist()):\n",
    "    x, y = map(int, center)\n",
    "    color = get_color(person_id)\n",
    "    cv2.circle(\n",
    "        image, (x, y), 20, color, 2, lineType=cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crey-ZdW865K"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "y5nisZMK0RKy"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# gdown.download(\n",
    "#     \"https://drive.google.com/uc?id=1SFOhg_vos_xSYHLMTDGFVZBYjo8cr2fG\", str(Path(data_dir, \"crowdhuman_dla34.pth\")), quiet=False\n",
    "# )\n",
    "# gdown.download(\n",
    "#     \"https://drive.google.com/uc?id=1iqRQjsG9BawIl8SlFomMg5iwkb6nqSpi\", str(Path(data_dir, \"fairmot_dla34.pth\")), quiet=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9nM_CpzUUQe"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from person_detection.centernet.src.pose_dla_dcn import get_pose_net as get_dla_dcn\n",
    "from src.trainer import Trainer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "num_layers = 34\n",
    "heads = {\"hm\": 1, \"wh\": 4, \"reg\": 2, \"id\": 128}\n",
    "head_conv = 256\n",
    "net = get_dla_dcn(num_layers, heads, head_conv)\n",
    "# model_path = Path(\"/home/jasseur/Downloads/crowdhuman_dla34.pth)\"\n",
    "model_path = Path(\"/home/jasseur/Downloads/fairmot_dla34.pth\")\n",
    "trainer = Trainer(\n",
    "    net, image_size=IMAGE_SIZE, device=\"cuda\", checkpoint_dir=\"checkpoint\",\n",
    "    nID=train_dataset.nID, model_path=model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(train_dataset, train_dataset, batch_size=4, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.eval(train_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fairmot-training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
